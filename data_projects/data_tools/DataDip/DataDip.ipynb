{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_altered_in = df_altered_out # run to save most recent alteration of df_altered_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prelims**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/results.csv'\n",
    "df = pd.read_csv(file_path) # original df\n",
    "#df = pd.read_excel(file_path)\n",
    "#df = pd.read_json(file_path)\n",
    "#df = pd.read_parquet(file_path)\n",
    "#df = pd.read_hdf(file_path, key='data')\n",
    "#df = pd.read_feather(file_path)\n",
    "#df = pd.read_clipboard()\n",
    "'''\n",
    "df_list = pd.read_html(url)  # Returns a list of DataFrames from HTML tables\n",
    "df = df_list[0]  # Assuming the desired DataFrame is the first one in the list\n",
    "'''\n",
    "'''\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('sqlite:///example.db')\n",
    "df = pd.read_sql_query('SELECT * FROM table_name', engine)\n",
    "'''\n",
    "\n",
    "df_altered_in = df # df to be altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Glance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_glance = df_altered_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_glance = df_altered_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_to_glance) # view head,tail of the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names list\n",
    "column_names = df_to_glance.columns\n",
    "print('Column Names:')\n",
    "print(str(column_names.tolist())+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows\n",
    "num_rows = df_to_glance.shape[0]\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns with null values\n",
    "columns_with_nulls = df_to_glance.columns[df_to_glance.isnull().any()]\n",
    "print('Columns with nulls: ')\n",
    "print(columns_with_nulls.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of nulls for columns\n",
    "\n",
    "columns_to_count_nulls = df_to_glance.columns # for all columns\n",
    "#columns_to_count_nulls = ['column1','column2',]\n",
    "\n",
    "# Calculate the number of null values for each column in the list\n",
    "null_counts = df_to_glance[columns_to_count_nulls].isnull().sum()\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique rows of any column. enter column name as string\n",
    "columns_to_check = df_to_glance.columns # all columns\n",
    "#columns_to_check = ['column_1','column_2',] # specific columns\n",
    "\n",
    "def get_unique_values(df, columns):\n",
    "    unique_values_dict = {col: df[col].unique() for col in columns}\n",
    "    return unique_values_dict\n",
    "\n",
    "unique_values_result = get_unique_values(df_to_glance, columns_to_check)\n",
    "print(unique_values_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types Checker: return type of each column and if there are mixed types\n",
    "\n",
    "# Function to check if there are mixed types in a column\n",
    "def check_mixed_types(column):\n",
    "    types = set(type(item) for item in column)\n",
    "    return len(types) > 1\n",
    "\n",
    "# Function to get the type(s) of a column\n",
    "def get_column_types(column):\n",
    "    return set(type(item) for item in column)\n",
    "\n",
    "# Check for mixed types in each column\n",
    "mixed_types = df_to_glance.apply(check_mixed_types)\n",
    "\n",
    "# Get the type(s) of each column\n",
    "column_types = df_to_glance.apply(get_column_types)\n",
    "\n",
    "# Display the results\n",
    "print(\"Columns with mixed types:\")\n",
    "print(mixed_types)\n",
    "\n",
    "print(\"\\nType(s) of each column:\")\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for value(s) in a column\n",
    "column_name_search = 'column1'\n",
    "search_values = [2, 4] # any type\n",
    "result = df_to_glance[df_to_glance[column_name_search].isin(search_values)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_glance.describe() # basic stats of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode(s)\n",
    "columns_to_mode = df_to_glance.columns # all columns\n",
    "#columns_to_mode = ['column1', 'column2'] # selected columns\n",
    "\n",
    "''' # to remove columns from all columns\n",
    "columns_to_remove = ['resultLink',] # columns to remove from full column list\n",
    "columns_to_mode = [col for col in columns_to_mode if col not in columns_to_remove]\n",
    "'''\n",
    "\n",
    "modes = df_to_glance[columns_to_mode].mode()\n",
    "modes.columns = [col for col in modes.columns]\n",
    "\n",
    "# Display the result\n",
    "print('Modes\\n')\n",
    "print(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(s)\n",
    "#columns_to_sum = df_to_glance.columns # all columns\n",
    "columns_to_sum = ['age', 'placeOverall', 'placeGender'] # selected columns\n",
    "\n",
    "''' # to remove columns from all columns\n",
    "columns_to_remove = ['resultLink',] # columns to remove from full column list\n",
    "columns_to_sum = [col for col in columns_to_sum if col not in columns_to_remove]\n",
    "'''\n",
    "\n",
    "sums_columns = df_to_glance[columns_to_sum].sum()\n",
    "\n",
    "print(\"Sums of Columns:\\n\", sums_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var(s)\n",
    "#columns_to_var = df_to_glance.columns # all columns\n",
    "columns_to_var = ['age', 'placeOverall', 'placeGender'] # selected columns\n",
    "\n",
    "''' # to remove columns from all columns\n",
    "columns_to_remove = ['resultLink',] # columns to remove from full column list\n",
    "columns_to_var = [col for col in columns_to_var if col not in columns_to_remove]\n",
    "'''\n",
    "\n",
    "vars_columns = df_to_glance[columns_to_var].var()\n",
    "\n",
    "print(\"Variance of Columns:\\n\", vars_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_clean = df_altered_in # df to be used for cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing null rows from all columns\n",
    "\n",
    "df_altered_out = df_to_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null rows from specific columns\n",
    "\n",
    "# list of columns to have null rows removed\n",
    "columns_to_drop_rows = ['column1', 'column2', 'column3']\n",
    "df_altered_out = df_to_clean.dropna(subset=columns_to_drop_rows)\n",
    "\n",
    "# uncomment if you want df altered\n",
    "#df = df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***`Filtering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_filter = df_altered_in # df to be filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Main Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main filter function\n",
    "def filter_main(df, conditions):\n",
    "    try:\n",
    "        # Use eval() to evaluate the conditions\n",
    "        filtered_df = df[df.eval(conditions)]\n",
    "        return filtered_df, None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error: {str(e)}\"\n",
    "        return None, error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = '(`Fatalities%` != Null)' # replace column_name, operator, value according to filter guide\n",
    "df_altered_out, error_filter = filter_main(df_to_filter, conditions) # call filter function\n",
    "\n",
    "if error_filter:\n",
    "    print(error_filter)\n",
    "else:\n",
    "    print(\"Data successfully filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``String Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter string function\n",
    "def filter_string(df, conditions_dict, case_sensitive):\n",
    "    try:\n",
    "        # If no conditions provided, return the original DataFrame\n",
    "        if not conditions_dict:\n",
    "            return None, \"No conditions provided.\"\n",
    "\n",
    "        # Initialize a boolean mask with True values\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "\n",
    "        # Apply conditions for each column in the conditions_dict\n",
    "        for column, condition in conditions_dict.items():\n",
    "            if column not in df.columns:\n",
    "                raise ValueError(f\"Invalid column name: {column}\")\n",
    "\n",
    "            mask &= df[column].str.contains(condition, case=case_sensitive)\n",
    "\n",
    "        # Use the boolean mask to filter the DataFrame\n",
    "        filtered_df = df[mask]\n",
    "        return filtered_df, None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error: {str(e)}\"\n",
    "        return None, error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_dict = {'column_name_1': 'substring_1', } # add more 'key':'value' pairs for more conditions\n",
    "case_sensitive = False # False for not case senstive\n",
    "df_altered_out, error = filter_string(df_to_filter, conditions_dict, case_sensitive)\n",
    "\n",
    "if error:\n",
    "    print(error)\n",
    "else:\n",
    "    print(\"Data filtered by string successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``List Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter based on list\n",
    "def filter_by_isin(df, conditions_dict, negate):\n",
    "    try:\n",
    "        # If no conditions provided, return the original DataFrame\n",
    "        if not conditions_dict:\n",
    "            return df, \"No conditions provided.\"\n",
    "\n",
    "        # Initialize a boolean mask with True values\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "\n",
    "        # Apply conditions for each column in the conditions_dict\n",
    "        for column, values in conditions_dict.items():\n",
    "            # Check if the column exists in the DataFrame\n",
    "            if column not in df.columns:\n",
    "                raise ValueError(f\"Invalid column name: {column}\")\n",
    "\n",
    "            # Use isin() to filter the DataFrame\n",
    "            condition = ~df[column].isin(values) if negate else df[column].isin(values)\n",
    "            mask &= condition\n",
    "\n",
    "        # Use the boolean mask to filter the DataFrame\n",
    "        filtered_df = df[mask]\n",
    "        return filtered_df, None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error: {str(e)}\"\n",
    "        return None, error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_dict = {'column_1': ['item_1', 'item_2'], 'column_2': ['item_3', 'item_4']} # dictionary for conditions. can contain >= 1 key,value pairs\n",
    "negate = False # set to False to not negate, set to True to negate\n",
    "df_altered_out, error = filter_by_isin(df_to_filter, conditions_dict, negate)\n",
    "\n",
    "if error:\n",
    "    print(error)\n",
    "else:\n",
    "    print(\"Data filtered by list successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Null Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter by null\n",
    "def filter_by_nulls(df, columns, is_null):\n",
    "    try:\n",
    "        # Check if all columns exist in the DataFrame\n",
    "        invalid_columns = [col for col in columns if col not in df.columns]\n",
    "        if invalid_columns:\n",
    "            raise ValueError(f\"Invalid column names: {', '.join(invalid_columns)}\")\n",
    "\n",
    "        # Initialize a boolean mask with True values\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "\n",
    "        # Apply isnull() or notnull() conditions for each specified column\n",
    "        for column in columns:\n",
    "            condition = df[column].isnull() if is_null else ~df[column].isnull()\n",
    "            mask &= condition\n",
    "\n",
    "        # Use the boolean mask to filter the DataFrame\n",
    "        filtered_df = df[mask]\n",
    "        return filtered_df, None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error: {str(e)}\"\n",
    "        return None, error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_null_filter = ['column_1', 'column_2'] # >=1 column names to check for nulls or not nulls\n",
    "is_null = True\n",
    "df_altered_out, error_null = filter_by_nulls(df_to_filter, columns_to_null_filter, is_null)\n",
    "\n",
    "if error_null:\n",
    "    print(error_null)\n",
    "else:\n",
    "    print(\"Filtered data by null/not_nulls successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***`Sorting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_sort = df_altered_in # the df to be sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by column function\n",
    "def sort_dataframe(df, sorting_dict):\n",
    "    try:\n",
    "        # Check if the sorting_dict is provided\n",
    "        if not sorting_dict:\n",
    "            return df, \"No sorting criteria provided.\"\n",
    "\n",
    "        # Validate columns in sorting_dict\n",
    "        invalid_columns = [col for col in sorting_dict.keys() if col not in df.columns]\n",
    "        if invalid_columns:\n",
    "            raise ValueError(f\"Invalid column names: {', '.join(invalid_columns)}\")\n",
    "\n",
    "        # Get column names and sorting orders from the dictionary\n",
    "        columns_to_sort = list(sorting_dict.keys())\n",
    "        ascending_order = list(sorting_dict.values())\n",
    "\n",
    "        # Use sort_values() to sort the DataFrame\n",
    "        df_sorted = df.sort_values(by=columns_to_sort, ascending=ascending_order)\n",
    "        return df_sorted, None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error: {str(e)}\"\n",
    "        return None, error_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_criteria = {'fatality/aboard ratio': True,} # column_name followed by True/False meaning ascending/descending\n",
    "df_altered_out, error_sort = sort_dataframe(df_to_sort, sorting_criteria)\n",
    "\n",
    "if error_sort:\n",
    "    print(error_sort)\n",
    "else:\n",
    "    print(\"Data sorted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_altered_out = df_to_sort.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Calculations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_calc = df_altered_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to execute a mathematical computation on columns and get a new column\n",
    "\n",
    "new_column = 'Fatalities%' # name new column\n",
    "\n",
    "# create your custom calculation. row['column_name'] is used for the row of each column\n",
    "def custom_calculation(row):\n",
    "    return row['Fatalities'] / row['Aboard']\n",
    "\n",
    "df_altered_out[new_column] = df_to_calc.apply(custom_calculation, axis=1)\n",
    "\n",
    "display(df_altered_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DF Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_create = df_altered_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df with removed columns\n",
    "columns_to_remove = ['fatality/aboard ratio']\n",
    "\n",
    "df_altered_out = df_to_create.drop(columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the type of 'Column1' to float\n",
    "column_to_convert = 'fatality/aboard ratio'\n",
    "convert_type = float\n",
    "df_to_create['Column1'] = df_to_create[column_to_convert].astype(convert_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df based on index range\n",
    "\n",
    "start_index = 0\n",
    "end_index = 10\n",
    "\n",
    "# Create a new DataFrame with rows from start_index to end_index\n",
    "new_df = df_to_create[start_index:end_index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df based on exact copy\n",
    "new_df = df_to_create.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df based on numerical condition of the rows\n",
    "\n",
    "desired_value = 5\n",
    "column_to_use = 'column_name'\n",
    "\n",
    "# replace with >,<,>=,<=\n",
    "new_df = df_to_create[df_to_create[column_to_use] > desired_value].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new_df with rows where 'column_name' matches 'desired_value'\n",
    "\n",
    "selected_value = 'desired_value'\n",
    "column_to_match = 'column_name'\n",
    "\n",
    "new_df = df_to_create[df_to_create[column_to_match] == selected_value].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new_df with specific columns only\n",
    "\n",
    "# add column names\n",
    "columns_to_keep = ['column1','column2',]\n",
    "\n",
    "new_df = df_to_create[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_altered_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_altered_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic histogram\n",
    "\n",
    "column_to_hist = 'Fatalities%'\n",
    "bin_size = 10\n",
    "\n",
    "plt.hist(df_plot[column_to_hist], bins=bin_size, color='blue', edgecolor='black')\n",
    "plt.xlabel(column_to_hist)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Histogram of {column_to_hist}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot\n",
    "\n",
    "column_to_line = 'finishTime'\n",
    "\n",
    "plt.plot(df_plot[column_to_line])\n",
    "plt.xlabel('Index')  # Assuming you want the x-axis to represent the index\n",
    "plt.ylabel(column_to_line)\n",
    "plt.title(f'Line Plot of {column_to_line}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart\n",
    "column_to_pie = 'fatality/aboard ratio'\n",
    "\n",
    "value_counts = df_plot[column_to_pie].value_counts() # unique values and their counts\n",
    "unique_values = value_counts.index.tolist()\n",
    "counts = value_counts.values.tolist()\n",
    "plt.figure(figsize=(8, 8))  # Adjust the figure size as needed\n",
    "plt.pie(counts, labels=unique_values, autopct='%1.1f%%', startangle=90)\n",
    "plt.title(f'Pie Chart of {column_to_pie}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart\n",
    "column_to_pie = 'Fatalities%'\n",
    "df_plot_pie = df_plot.copy() # this is done to avoid type issues if grouping, no overwriting df_plot\n",
    "\n",
    "'''\n",
    "# Grouping values less than 0.2 together\n",
    "grouped_condition = df_plot_pie[column_to_pie] < 1.0\n",
    "group_label = '< 1.0'\n",
    "\n",
    "# Use numpy.where to conditionally replace values\n",
    "df_plot_pie[column_to_pie] = np.where(grouped_condition, group_label, df_plot_pie[column_to_pie])\n",
    "'''\n",
    "\n",
    "value_counts = df_plot_pie[column_to_pie].value_counts() # unique values and their counts\n",
    "unique_values = value_counts.index.tolist()\n",
    "counts = value_counts.values.tolist()\n",
    "plt.figure(figsize=(8, 8))  # Adjust the figure size as needed\n",
    "plt.pie(counts, labels=unique_values, autopct='%1.1f%%', startangle=90)\n",
    "plt.title(f'Pie Chart of {column_to_pie}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custom**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
